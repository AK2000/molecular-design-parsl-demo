{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde9731c-1900-40b6-a431-3c86975b1ce3",
   "metadata": {},
   "source": [
    "# Molecular Design with Parsl\n",
    "This notebook demonstrates a simple molecular design application where we use machine learning to guide which computations we perform.\n",
    "The objective of this demo is to find which molecules have the large ionization energies (IE, the amount of energy required to remove an electron)\n",
    "where we employ machine learning to predict high IE molecules based on previous computations (a process [often called active learning](https://pubs.acs.org/doi/abs/10.1021/acs.chemmater.0c00768)). \n",
    "\n",
    "![workflow](./figures/workflow.svg)\n",
    "\n",
    "In this notebook, you will see how to use Parsl to execute functions in parallel and how Parsl's integration with Python's native concurrency library (i.e., [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)) let you write apps that dynamically respond to the completion of asynchronous tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bcace9-64ab-4ccf-80f7-35cf0a548e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from chemfunctions import compute_vertical\n",
    "from concurrent.futures import as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.app.python import PythonApp\n",
    "from parsl.app.app import python_app\n",
    "from parsl.config import Config\n",
    "from time import monotonic\n",
    "import parsl\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d062e-4675-4c39-a1cb-d036d1d141ec",
   "metadata": {},
   "source": [
    "## Define problem\n",
    "The configuration parameters for the app: The search space of molecules and parameters controlling the optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d4dfebd-6559-42e7-adad-140337e3968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = pd.read_csv('data/QM9-search.tsv', delim_whitespace=True).sample(1024)  # Our search space of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5341682-6042-4534-8838-11b779cef16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count: int = 8  # Number of calculations to run at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf04db9-5df4-42d9-b2e4-715b1e45aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_count: int = 16   # Number of molecules to evaluate in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e836cf85-4cc9-4bfc-bb13-74b28cef0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size: int = 4  # Number of molecules to evaluate in each batch of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c41cb4-7b27-477e-8248-10023b176279",
   "metadata": {},
   "source": [
    "## Set up Parsl\n",
    "Our first step is to initialize Parsl.\n",
    "\n",
    "The following will configure Parsl to run tasks on the local machine. This is where we would describe the details of (for example) a supercomputer, if we wanted to execute tasks there instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995a2330-8e35-4966-b7de-b99f23c5f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    executors=[HighThroughputExecutor(\n",
    "        label='local',\n",
    "        max_workers=2, # Allows a maximum of two workers \n",
    "        cpu_affinity='block'  # Assigns workers to specific cores\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393cf69b-ed97-4a7b-88e5-e72bb9898cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.dataflow.dflow.DataFlowKernel at 0x7fdee497ff40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsl.load(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9296aa-4d27-4098-83dd-34da8995681a",
   "metadata": {},
   "source": [
    "## Make an initial dataset\n",
    "We need data to train our ML models. We'll do that by selecting a set of molecules at random from  our search space, performing some simulations on those molecules, and training on the results.\n",
    "\n",
    "In [`chemfunctions.py`](./chemfunctions.py), we have defined a function `compute_vertical` that computes the \"vertical ionization energy\" of a molecule (a measure of how much energy it takes to strip an electron off the molecule). `compute_vertical` takes a string representation of a molecule in [SMILES format](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) as input and returns the ionization energy as a float. Under the hood, it is running [xTB](https://xtb-docs.readthedocs.io/en/latest/contents.html) to perform a series of quantum chemistry computations.\n",
    "\n",
    "We need to prepare this function to run with Parsl. All we need to do is wrap this function with Parsl's `python_app` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7836093-dad6-429f-966c-13c9c2a2f741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<parsl.app.python.PythonApp at 0x7fdee1189d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_vertical_app = python_app(compute_vertical)\n",
    "compute_vertical_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef5766-02ed-4f2d-8e7f-021df8e0df1c",
   "metadata": {},
   "source": [
    "This new object is a Parsl `PythonApp`. It can be invoked like the original function, but instead of immediately executing, the function wil be scheduled to run inside Parsl asynchronously. Instead of the result, the call will immediately return a `Future` which will be used to retrieve the result later on.\n",
    "\n",
    "For example, invoking compute_verticle_app with the SMILES for water, `O`, returns a Future and schedules `compute_verticle` for execution in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc12a88-d7bf-472a-9766-cf7444b16a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AppFuture super=<AppFuture at 0x7fdee1189a90 state=pending>>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future = compute_vertical_app('O') #  Run water as a demonstration (O is the SMILES for water) # TODO: is it water or a single oxygen?\n",
    "future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c086c0",
   "metadata": {},
   "source": [
    "We can access the result of this computation by asking the future for the `result()`. If the computation isn't finished yet, then the call to `.result()` will block until the result is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d87ff886-ff13-4c3e-8708-ca6f20a209ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ionization energy of O is 0.67 Ha\n"
     ]
    }
   ],
   "source": [
    "ie = future.result()\n",
    "print(f\"The ionization energy of {future.task_def['args'][0]} is {ie:.2f} Ha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56264dd2-af71-4dce-9f28-b25dd74cbdcc",
   "metadata": {},
   "source": [
    "Ok, now lets run the simulation for several different molecules and gather their results.\n",
    "\n",
    "First we submit them, all at once. Each invocation returns a `Future` immediately, so this code should finish within a few milliseconds.\n",
    "\n",
    "Because we never call `.result()`, this code does not wait for any results to be ready. Instead, Parsl is running the computations in the background. Parsl manages sending work to each worker process, collecting results, and feeding new work to workers as new tasks are submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1becbe-7616-431e-90fd-7030ca85680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted 8 calculations to start with\n",
      "CPU times: user 4.02 ms, sys: 0 ns, total: 4.02 ms\n",
      "Wall time: 4.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "smiles = search_space.sample(initial_count)['smiles']\n",
    "futures = [compute_vertical_app(s) for s in smiles]\n",
    "print(f'Submitted {len(futures)} calculations to start with')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea4cbc-468c-4016-8086-0d4226fce119",
   "metadata": {},
   "source": [
    "The futures Parsl produces are based on Python's [native \"Future\"](https://docs.python.org/3/library/concurrent.futures.html#future-objects) object,\n",
    "so we can use Python's utility functions to work with them.\n",
    "\n",
    "As an example, we can build a loop that submits new computations if previous ones fail. This happens not too infrequently with our simulation application.\n",
    "\n",
    "This example uses another method, `Future.exception()`. This is similar to `Future.result()`. It will block until the relevant task is completed, but rather than the result, it returns any exception that was raised during exception (or `None` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c72186e7-acbb-4d37-b957-339ff9de8951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation for N=C1C=NOC(C=O)=C1 succeeded\n",
      "Computation for N#CCC12CN1CC=C2 succeeded\n",
      "Computation for CC1CC2(CC12C)C=O succeeded\n",
      "Computation for CC1(CO1)C12CC1CO2 succeeded\n",
      "Computation for OC1CC1(CC#N)C#N succeeded\n",
      "Computation for CC1(C)OC(C#N)C1O succeeded\n",
      "Computation for C1CC23OC(CC=C2)C13 failed, submitting a replacement computation\n",
      "Computation for C1C=CC2C3C=CC1N23 succeeded\n",
      "Computation for COC1=NNC(N)=C1 succeeded\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "while len(futures) > 0: \n",
    "    # First, get the next completed computation from the list\n",
    "    future = next(as_completed(futures))\n",
    "    \n",
    "    # Remove it from the list of still-running tasks\n",
    "    futures.remove(future)\n",
    "    \n",
    "    # Get the input \n",
    "    smiles = future.task_def['args'][0]\n",
    "    \n",
    "    # Check if the run completed successfully\n",
    "    if future.exception() is not None:\n",
    "        # If it failed, pick a new SMILES string at random and submit it    \n",
    "        print(f'Computation for {smiles} failed, submitting a replacement computation')\n",
    "        smiles = search_space.sample(1).iloc[0]['smiles'] # pick one molecule\n",
    "        new_future = compute_vertical_app(smiles) # launch a simulation in Parsl\n",
    "        futures.append(new_future) # store the Future so we can keep track of it\n",
    "    else:\n",
    "        # If it succeeded, store the result\n",
    "        print(f'Computation for {smiles} succeeded')\n",
    "        train_data.append({\n",
    "            'smiles': smiles,\n",
    "            'ie': future.result(),\n",
    "            'batch': 0,\n",
    "            'time': monotonic()\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c44dfd-ce2d-4e60-b208-0a40abe61e36",
   "metadata": {},
   "source": [
    "We now have an initial set  of training data: a pandas `DataFrame` containing the randomly samples molecules alongside the simulated ionization energy (`ie`). In addition, the code above has stored some metadata (`batch` and `time`) which we will use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256b9191-17b1-4b65-9883-4ad7a86f63d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>ie</th>\n",
       "      <th>batch</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N=C1C=NOC(C=O)=C1</td>\n",
       "      <td>0.507545</td>\n",
       "      <td>0</td>\n",
       "      <td>22117.538182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N#CCC12CN1CC=C2</td>\n",
       "      <td>0.490594</td>\n",
       "      <td>0</td>\n",
       "      <td>22121.836437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1CC2(CC12C)C=O</td>\n",
       "      <td>0.489504</td>\n",
       "      <td>0</td>\n",
       "      <td>22146.784515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC1(CO1)C12CC1CO2</td>\n",
       "      <td>0.501569</td>\n",
       "      <td>0</td>\n",
       "      <td>22151.394323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OC1CC1(CC#N)C#N</td>\n",
       "      <td>0.534034</td>\n",
       "      <td>0</td>\n",
       "      <td>22165.545437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CC1(C)OC(C#N)C1O</td>\n",
       "      <td>0.520492</td>\n",
       "      <td>0</td>\n",
       "      <td>22165.890198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C1C=CC2C3C=CC1N23</td>\n",
       "      <td>0.465306</td>\n",
       "      <td>0</td>\n",
       "      <td>22186.515542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COC1=NNC(N)=C1</td>\n",
       "      <td>0.472285</td>\n",
       "      <td>0</td>\n",
       "      <td>22187.057632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              smiles        ie  batch          time\n",
       "0  N=C1C=NOC(C=O)=C1  0.507545      0  22117.538182\n",
       "1    N#CCC12CN1CC=C2  0.490594      0  22121.836437\n",
       "2   CC1CC2(CC12C)C=O  0.489504      0  22146.784515\n",
       "3  CC1(CO1)C12CC1CO2  0.501569      0  22151.394323\n",
       "4    OC1CC1(CC#N)C#N  0.534034      0  22165.545437\n",
       "5   CC1(C)OC(C#N)C1O  0.520492      0  22165.890198\n",
       "6  C1C=CC2C3C=CC1N23  0.465306      0  22186.515542\n",
       "7     COC1=NNC(N)=C1  0.472285      0  22187.057632"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbeb14c-585d-478c-9bcf-35668643138a",
   "metadata": {},
   "source": [
    "## Train an initial machine learning model, use to screen candidates\n",
    "Our next step for Parsl is to produce a machine learning model to estimate the outcome of new computations and use it to scan the search space.\n",
    "\n",
    "To start, let's make a function that takes our existing data and uses it to train a model. We are going to use RDKit and scikit-learn to train a nearest-neighbor model that uses Morgan fingerprints to define similarity (see [notes from a UChicago AI course](https://github.com/WardLT/applied-ai-for-materials/blob/main/molecular-property-prediction/chemoinformatics/2_ml-with-fingerprints.ipynb) for more detail). In short, the function trains a model that first populates a list of whether certain substructures (Morgan fingerprints, specifically) and then trains a model which predicts the IE of a new molecule by averaging those with the most similar substructures.\n",
    "\n",
    "We want it to run in Parsl, so we create the function using `python_app`. This time, `python_app` is used as a decorator directly on the function definition (earlier we defined a regular function, and then applied `python_app` afterwards)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c59349-4b19-4647-89cd-3ff2b0eb23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def train_model(train_data):\n",
    "    \"\"\"Train a machine learning model using Morgan Fingerprints.\n",
    "    \n",
    "    Args:\n",
    "        train_data: Dataframe with a 'smiles' and 'ie' column\n",
    "            that contains molecule structure and property, respectfully.\n",
    "    Returns:\n",
    "        A trained model\n",
    "    \"\"\"\n",
    "    # Imports for python functions run remotely must be defined inside the function\n",
    "    from chemfunctions import MorganFingerprintTransformer\n",
    "    from sklearn.neighbors import KNeighborsRegressor\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    \n",
    "    model = Pipeline([\n",
    "        ('fingerprint', MorganFingerprintTransformer()),\n",
    "        ('knn', KNeighborsRegressor(n_neighbors=4, weights='distance', metric='jaccard', n_jobs=-1))  # n_jobs = -1 lets the model run all available processors\n",
    "    ])\n",
    "    \n",
    "    return model.fit(train_data['smiles'], train_data['ie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641bd1e4-e796-4b88-9ef1-2d941ba0acd8",
   "metadata": {},
   "source": [
    "Let's start it to run asynchronously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e20adb-985d-42c7-9495-2df58f84e7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_future = train_model(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3b3e8-8e9c-40a5-b8e7-ec33bc2fdb82",
   "metadata": {},
   "source": [
    "A great feature of Parsl is that it can create workflows on-the-fly from Python: chains of functions that can run in parallel when possible, waiting on dependencies as necessary.  **TODO: is this a relevant workflow definition for this tutorial?\n",
    "\n",
    "To do so, we pass the future created by executing one function an input to another Parsl function.\n",
    "\n",
    "As an example, let's create a function that uses the trained model to run inference on a large set of molecules and then another that takes many predictions and contatenates them into a single collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b58363d1-c843-4df7-990a-b3f679c4f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def run_model(model, smiles):\n",
    "    \"\"\"Run a model on a list of smiles strings\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model that takes SMILES strings as inputs\n",
    "        smiles: List of molecules to evaluate\n",
    "    Returns:\n",
    "        A dataframe with the molecules and their predicted outputs\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    pred_y = model.predict(smiles)\n",
    "    return pd.DataFrame({'smiles': smiles, 'ie': pred_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "629f46d2-4f5c-4a94-9073-e5389a38759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@python_app\n",
    "def combine_inferences(inputs=[]):\n",
    "    \"\"\"Concatenate a series of inferences into a single DataFrame\n",
    "    Args:\n",
    "        inputs: a list of the component DataFrames\n",
    "    Returns:\n",
    "        A single DataFrame containing the same inferences\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    return pd.concat(inputs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4952a58",
   "metadata": {},
   "source": [
    "Now we've made our definitions, we can chop up the search space into chunks, and invoke `run_model`  once for each chunk of the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d42cb1dc-f2ed-4a26-bf5e-415b63947a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk the search space into smaller pieces, so that each can run in parallel\n",
    "chunks = np.array_split(search_space['smiles'], 64)\n",
    "inference_futures = [run_model(train_future, chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30adf3b9",
   "metadata": {},
   "source": [
    "... and then combine the collections into a single DataFrame using `combine_inferences`.\n",
    "\n",
    "Parsl will automatically arrange execution so that `train_future` must complete before any of the `run_model` tasks start; and all of the `run_model` tasks must be finished before `combine_inferences` starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57a9a309-9f38-4e11-8e77-1dea84f3bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pass the inputs explicitly as a named argument \"inputs\" for Parsl to recognize this as a \"reduce\" step\n",
    "#  See: https://parsl.readthedocs.io/en/stable/userguide/workflow.html#mapreduce\n",
    "predictions = combine_inferences(inputs=inference_futures).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2577f6d",
   "metadata": {},
   "source": [
    "We can print out the best five molecules, according to the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2640c439-f553-47d6-ae89-b168299b1827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>ie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>OC1CC1(CC#N)C#N</td>\n",
       "      <td>0.534034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>CC1(C)OC(C#N)C1O</td>\n",
       "      <td>0.520492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>OC1COC(=O)C1O</td>\n",
       "      <td>0.516672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>C#CCCC1OCCO1</td>\n",
       "      <td>0.516540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>OC1C2OC2C1(O)C#C</td>\n",
       "      <td>0.516466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               smiles        ie\n",
       "930   OC1CC1(CC#N)C#N  0.534034\n",
       "434  CC1(C)OC(C#N)C1O  0.520492\n",
       "862     OC1COC(=O)C1O  0.516672\n",
       "278      C#CCCC1OCCO1  0.516540\n",
       "895  OC1C2OC2C1(O)C#C  0.516466"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sort_values('ie', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b95b0-040a-411b-bb49-cf1ab8f3d1ca",
   "metadata": {},
   "source": [
    "We now have the ability to train a model and use it to identify molecules that are likely to be good next choices for simulations. Time to build a model-in-the-loop workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe44cc03-1d77-4b0d-a09b-e2895d21210a",
   "metadata": {},
   "source": [
    "## Model-in-the-Loop Workflow\n",
    "We are going to build an application that uses a machine learning model to pick a batch of simulations, runs the simulations in parallel, and then uses the data to retrain the model before repeating the loop.\n",
    "\n",
    "This code uses `train_model`, `run_model` and `combine_inferences` as above, but repeatedly retrains the model using the predicted best molecules of each iteration until a fixed number of molecule simulations have been trained against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "656921aa-343c-481f-bc40-5b97e8720e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5dfb06e4277409cad7c3776874ea718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tqdm(total=search_count) as prog_bar: # setup a graphical progress bar\n",
    "    prog_bar.update(len(train_data))\n",
    "    batch = 1\n",
    "    already_ran = set(train_data['smiles'])\n",
    "    while len(train_data) < search_count:\n",
    "        # Train and predict as show in the previous section.\n",
    "        train_future = train_model(train_data)\n",
    "        inference_futures = [run_model(train_future, chunk) for chunk in np.array_split(search_space['smiles'], 64)]\n",
    "        predictions = combine_inferences(inputs=inference_futures).result()\n",
    "\n",
    "        # Sort the predictions in descending order, and submit new molecules from them\n",
    "        predictions.sort_values('ie', ascending=False, inplace=True)\n",
    "        sim_futures = []\n",
    "        for smiles in predictions['smiles']:\n",
    "            if smiles not in already_ran:\n",
    "                sim_futures.append(compute_vertical_app(smiles))\n",
    "                already_ran.add(smiles)\n",
    "                if len(sim_futures) >= batch_size:\n",
    "                    break\n",
    "\n",
    "        # Wait for every task in the current batch to complete, and store successful results\n",
    "        new_results = []\n",
    "        for future in as_completed(sim_futures):\n",
    "            if future.exception() is None:\n",
    "                prog_bar.update(1)\n",
    "                new_results.append({\n",
    "                    'smiles': future.task_def['args'][0],\n",
    "                    'ie': future.result(),\n",
    "                    'batch': batch, \n",
    "                    'time': monotonic()\n",
    "                })\n",
    "                \n",
    "        # Update the training data and repeat\n",
    "        batch += 1\n",
    "        train_data = pd.concat((train_data, pd.DataFrame(new_results)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f5168-ba88-469a-9ace-8c6574d5aa7f",
   "metadata": {},
   "source": [
    "We can plot the training data against the time of simulation, showing that the model was finding better molecules later on in the run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215f8ee9-b61f-4e2a-975f-c940f87c3d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['time'] = train_data['time'] - train_data['time'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d58f722-0250-44e7-86bd-6f664c67a837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 324x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5, 3.))\n",
    "\n",
    "ax.scatter(train_data['time'], train_data['ie'])\n",
    "ax.step(train_data['time'], train_data['ie'].cummax(), 'k--')\n",
    "\n",
    "ax.set_xlabel('Walltime (s)')\n",
    "ax.set_ylabel('Ion. Energy (Ha)')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb145f7-1aac-453c-85d6-328a01b71b27",
   "metadata": {},
   "source": [
    "You can see how our search program finds better molecules over time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20705de3-ff9f-4316-b845-9e036f34d2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0cacceed9db4464f9f414274519b4949": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "252de14e22c54080bfcaff0574d898d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "270ad7c288c14ba2af5fe1cd642a09eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6fe9c731cdc640ad858660f64c387dc4",
       "placeholder": "​",
       "style": "IPY_MODEL_fe7006dbf4824d898f4f010f87b1c6f2",
       "value": " 70/? [01:05&lt;00:00,  1.26s/it]"
      }
     },
     "474ddeec4b9e40f5a89f9c7b67ea31e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0cacceed9db4464f9f414274519b4949",
       "placeholder": "​",
       "style": "IPY_MODEL_d4c9ca989df549f09c7ce94ee74c6a57",
       "value": ""
      }
     },
     "6fe9c731cdc640ad858660f64c387dc4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84f635e5b62a44c0b110315fb375c321": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad75de48e1324ca3993fc8cf8b31a853",
       "max": 64,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_252de14e22c54080bfcaff0574d898d4",
       "value": 64
      }
     },
     "91420bed062b46e9b5c2a914377ed68f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad75de48e1324ca3993fc8cf8b31a853": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb5f4153b6a44eac8cec5ed6fc6923ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_474ddeec4b9e40f5a89f9c7b67ea31e6",
        "IPY_MODEL_84f635e5b62a44c0b110315fb375c321",
        "IPY_MODEL_270ad7c288c14ba2af5fe1cd642a09eb"
       ],
       "layout": "IPY_MODEL_91420bed062b46e9b5c2a914377ed68f"
      }
     },
     "d4c9ca989df549f09c7ce94ee74c6a57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fe7006dbf4824d898f4f010f87b1c6f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
