{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455b6ae0-55de-4d2b-b6ee-0f4ac3434896",
   "metadata": {},
   "source": [
    "# Interleaving Simulation and Steering\n",
    "We use a batch strategy [in our previous example](./molecular-design-with-parsl.ipynb) that, while simple to implement, leads to under-utilization.\n",
    "The core problem of a batch strategy is that only one type of task - simulation, training, or inference - at a single time.\n",
    "The serial nature results in several points during the workflow where either there are not enough tasks (e.g., one model to train)\n",
    "or tail-down loses while we wait for the last tasks from a batch to complete before starting the next type.\n",
    "This example shows how to increase parallelism by using [Colmena](https://colmena.readthedocs.io/en/latest/) to run multiple kinds of tasks concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d92d3d-99c6-4f1b-8246-fb3ff59c32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from colmena.models import Result\n",
    "from colmena.task_server.parsl import ParslTaskServer\n",
    "from colmena.redis.queue import make_queue_pairs\n",
    "from colmena.thinker.resources import ResourceCounter\n",
    "from colmena.thinker import BaseThinker, event_responder, task_submitter, result_processor\n",
    "from parsl.executors import HighThroughputExecutor\n",
    "from parsl.config import Config\n",
    "from random import shuffle\n",
    "from threading import Lock\n",
    "from typing import List\n",
    "from chemfunctions import compute_vertical, train_model, run_model\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8408f6-247d-41c9-be5a-957c04699547",
   "metadata": {},
   "source": [
    "## Load in the Data\n",
    "We're going to use the same problem as the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf35efa-6f01-45fb-a788-1a839ea1441b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = pd.read_csv('data/QM9-search.tsv', delim_whitespace=True).sample(1024)  # Our search space of molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3a9145-4cdb-4178-bcf9-1254486e4de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_count: int = 8  # Number of calculations to run at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfaba0e-a191-492d-b4e0-976210f30cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_count: int = 16   # Number of molecules to evaluate in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4b51cb-8ee4-47e2-85fd-b12ca3054696",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size: int = 4  # Number of molecules to evaluate in each batch of simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165328c-de76-4d96-8053-1ba3297989c3",
   "metadata": {},
   "source": [
    "## Configuring the Task Server\n",
    "Colmena applications have three parts: a _Task Server_ that performs work at the direction of a _Thinker_ through a _Task Queue_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05680f7-6c57-4dce-8bf6-d3bb3e08981f",
   "metadata": {},
   "source": [
    "### Creating Task Queue\n",
    "A task queue is responsible for conveying requests to perform a computation to a Task Server, and then supplying results back to the Thinker.\n",
    "Creating a task queue requires defining connection information to Redis and the names of separate topics used to separate different kinds of tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab75772a-91c9-4ef3-8e30-a13f43da9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_queues, server_queues = make_queue_pairs(hostname='localhost', topics=['simulate', 'train', 'infer'], serialization_method='pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ee709-465f-40c5-9c27-9a5a25119660",
   "metadata": {},
   "source": [
    "### Defining Task Server\n",
    "The Task Server requires a task queue to communicate through, a list of methods, and a set of computational resources to run them on. (See [Colmena Docs](https://colmena.readthedocs.io/en/latest/how-to.html#configuring-a-task-server))\n",
    "\n",
    "The computation resources are defined using Parsl's definitions. We'll use the same one as the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693927c6-1a00-40e5-a291-729a3d7f805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    executors=[HighThroughputExecutor(\n",
    "        max_workers=2, # Allows a maximum of two workers\n",
    "        cpu_affinity='block' # Prevents workers from using the same cores\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ada804-444c-4461-a064-816e47558bff",
   "metadata": {},
   "source": [
    "We supply a list of Python functions to define the methods and also give the constructor a link to the queues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f1688d4-1bcc-4fd5-902e-803afdf4caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_server = ParslTaskServer(\n",
    "    methods=[compute_vertical, train_model, run_model],\n",
    "    queues=server_queues,\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803bca2-8aa9-4172-8314-59328cc4b767",
   "metadata": {},
   "source": [
    "The task server runs in the background. \n",
    "> *NOTE*: You must kill it before exiting the notebook by sending a kill signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82fde165-0122-4d47-8ec7-23a92f2983c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_server.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b3a74c-5c5a-4412-b36a-e7b026bdddf7",
   "metadata": {},
   "source": [
    "The server will run tasks on request from a queue and send them back on a different Redis queue.\n",
    "The client queue object provides a `send_inputs` and `get_result` method to perform these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7293bc-f33f-41e1-bc51-b66333bebda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.35 ms, total: 3.35 ms\n",
      "Wall time: 3.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "client_queues.send_inputs('C', method='compute_vertical')\n",
    "result = client_queues.get_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9220cd0f-0c78-4841-8ea0-a866d7425a49",
   "metadata": {},
   "source": [
    "Both accept a \"topic\" option that allows for multiplexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca72bba-62b1-44b9-b097-e3594295da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_queues.send_inputs('C', method='compute_vertical', topic='simulate')\n",
    "\n",
    "# Show that we do not pull results on other topics\n",
    "result = client_queues.get_result(topic='infer', timeout=15)\n",
    "assert result is None  # None means a timeout occurred\n",
    "\n",
    "# Pull from the correct queue\n",
    "result = client_queues.get_result(topic='simulate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e27d3-5d1c-431b-abb9-ad53928de225",
   "metadata": {},
   "source": [
    "Shut down the system for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b940d-d80f-46ac-9d95-606b857c0c2c",
   "metadata": {},
   "source": [
    "## Building a Thinker\n",
    "The Thinker part of a Colmena application coordinates what tasks are run by the Task Server.\n",
    "\n",
    "Thinker applications are built using a collection of threads (\"agents\") that cooperate to perform some task. \n",
    "For example, you can have an agent that records a simulation being completed and launches a second agent that manages retraining the models.\n",
    "\n",
    "Below, we walk through how to build a thinker application though progressively more complex examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3171fc7-53ee-4cc4-8db6-047a967d20aa",
   "metadata": {},
   "source": [
    "### Example 1: Simulating molecules in a predefined list\n",
    "A steering policy in Colmena is defined through a [Thinker](https://colmena.readthedocs.io/en/latest/how-to.html#creating-a-thinker-application) class. \n",
    "The Thinker class has methods which can run as parallel threads and share information with each other via class attributes, \n",
    "which always includes a \"resource allocation tracker\" used to signal when resources are free.\n",
    "\n",
    "A simple example for a Thinker is one that submits a new calculation from a list when another completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70e58d4f-0095-4365-863b-1831aca433ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleThinker(BaseThinker):\n",
    "    \n",
    "    def __init__(self, queues, n_to_evaluate: int, n_parallel: int, \n",
    "                 molecule_list: List[str]):\n",
    "        \"\"\"Initialize the thinker\n",
    "        \n",
    "        Args:\n",
    "            queues: Client side of queues\n",
    "            n_to_evaluate: Number of molecules to evaluate\n",
    "            n_parallel: Number of computations to run in parallel\n",
    "            molecule_list: List of SMILES strings\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            queues, \n",
    "            ResourceCounter(n_parallel, ['simulate', 'train', 'infer'])\n",
    "        )\n",
    "        \n",
    "        # Store the user settings\n",
    "        self.molecule_list = set(molecule_list)\n",
    "        self.n_to_evaluate = n_to_evaluate\n",
    "        \n",
    "        # Create a database of evaluated molecules\n",
    "        self.database = dict()\n",
    "        \n",
    "        # Create a record of completed calculations\n",
    "        self.computations = []\n",
    "        \n",
    "        # Create a priority list of molecules, starting with them ordered randomly\n",
    "        self.priority_list = list(self.molecule_list)\n",
    "        shuffle(self.priority_list)\n",
    "        self.priority_list_lock = Lock()  # Ensures two agents cannot use it \n",
    "        \n",
    "        # Create a tracker for how many sent and how many complete\n",
    "        self.rec_progbar = tqdm(total=n_to_evaluate, desc='started')\n",
    "        self.sent_progbar = tqdm(total=n_to_evaluate, desc='successful')\n",
    "        \n",
    "        # Assign all of the resources over to simulation\n",
    "        self.rec.reallocate(None, 'simulate', n_parallel)\n",
    "        \n",
    "    @task_submitter(task_type='simulate', n_slots=1)\n",
    "    def submit_calc(self):\n",
    "        \"\"\"Submit a calculation when resources are available\"\"\"\n",
    "        \n",
    "        with self.priority_list_lock:\n",
    "            next_mol = self.priority_list.pop()  # Get the next best molecule\n",
    "        \n",
    "        # Send it to the task server to run\n",
    "        self.queues.send_inputs(next_mol, method='compute_vertical')\n",
    "        self.rec_progbar.update(1)\n",
    "        \n",
    "    @result_processor\n",
    "    def receive_calc(self, result: Result):\n",
    "        \"\"\"Store the output of a run if it is successful\"\"\"\n",
    "        \n",
    "        # Mark that the resources are now free\n",
    "        self.rec.release('simulate', 1)\n",
    "        \n",
    "        # Store the result if successful\n",
    "        if result.success:\n",
    "            # Store the result in a database\n",
    "            self.database[result.args[0]] = result.value\n",
    "            \n",
    "            # Mark that we've received a result\n",
    "            self.sent_progbar.update(1)\n",
    "            \n",
    "            # If we've got all of the simulations complete, stop\n",
    "            if len(self.database) >= self.n_to_evaluate:\n",
    "                self.done.set()\n",
    "            \n",
    "        # Store the result object for later processing\n",
    "        self.computations.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c660f740-da57-44f0-a8d8-b6a084517323",
   "metadata": {},
   "source": [
    "We instantiate a copy of this thinker with the settings we want and then call `run` to start it working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22aca2cb-972c-4eaf-9ffd-f21011a4c7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4439cc1fb6b41caa2391bf1fc057f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "started:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd05833698c443f823ccfb5d3d11074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "successful:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thinker = ExampleThinker(client_queues, search_count, 2, search_space['smiles'].values)\n",
    "thinker.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ef47c-ee54-4b0f-a7c7-0b64ac92843e",
   "metadata": {},
   "source": [
    "Watch how the thinker only start new calculations after another one finishes. \n",
    "The ability to throttle will be important when we don't know which calculations to submit next until others have finished.\n",
    "\n",
    "> The thinker will receive more than the requested number of calculations, as we stop submitting only after enough have completed and wait until all submitted tasks complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c44bb-24ca-4b2a-819b-f0cbfb53979a",
   "metadata": {},
   "source": [
    "## Wrap up\n",
    "Once complete, we send a \"kill\" signal to shutdown the task server. The task server will clean up any computational resources being used, then exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b3f14f9-8788-49e4-8e30-e8f442d4ce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process exited with 0 code\n"
     ]
    }
   ],
   "source": [
    "client_queues.send_kill_signal()\n",
    "task_server.join()\n",
    "print(f'Process exited with {task_server.exitcode} code')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
